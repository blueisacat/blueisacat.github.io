---
layout: default
title: 4.算法课程学习笔记-多目标检测识别
parent: AI
nav_order: 5
---

### 1. 目标检测识别的发展

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_0.png)

- 阶段1：单目标，分类

- 阶段2：单目标，分类+定位

- 阶段3：多目标，目标检测

- 阶段4：多目标，实例分割

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_1.png)

### 2. RCNN系列技术原理

#### 2.1 RCNN

在RCNN刚刚被发明出来的2014年，RCNN在目标检测与行人检测上取得了巨大的成就，然而效率低下，花费时间长等一系列的问题的产生，还是导致了RCNN的运用并没有取得大范围的应用，其最大的问题有三：

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_2.png)

- 需要事先提取多个候选区域对应的图像，这一行为会占用大量的磁盘空间

- 针对传统的CNN来说，输入的map需要是固定尺寸的，而归一化过程中对图片产生的形变会导致图片大小改变，这对CNN的特征提取有致命的坏处

- 每个候选框都需要进入CNN网络计算，进而会导致过多次的重复的相同特征提取，这一举动会导致大大的计算浪费

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_3.png)

R-CNN算法的流程如下：

1. 输入图像

1. 使用selective search的传统聚类算法在每张图像上生成1K~2K个候选区域

1. 对每个候选区域，使用深度网络提取特征（AlextNet、VGG等CNN都可以）

1. 将特征送入每一类的SVM分类器，判别是否属于该类

1. 使用回归器精细修正候选框位置

#### 2.2 Selective Search

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_4.png)

selective search的策略是，我们在检测目标时是不知道目标的尺寸的，既然不知道尺寸是怎样的，那我们就尽可能遍历所有的尺寸，但是不同于暴力穷举，我们可以先得到小尺寸的区域，然后一次次合并得到大的尺寸就好了，这样也符合人类的视觉认知，简而言之，就是合并相似的特征区域。

selective search方法主要有三个优势：

- 捕捉不同尺寸

- 多样化

- 快速计算

总结为：selective search是用于目标检测的区域提议算法，它计算速度快，具有很高的召回率，基于颜色，纹理，大小和形状兼容计算相似区域的分层分组。

#### 2.3 Fast RCNN

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_5.png)

2015年推出Fast R-CNN，构思精巧，流程更为紧凑，大幅提升了目标检测的速度。

Fast R-CNN和R-CNN相比，训练时间从84小时减少到9.5小时，测试时间从47秒减少到0.32秒。在Fast R-CNN中，将从原图选出聚类候选框的方法改成了从CNN层之后选出的特征图上聚类候选框的方法，筛选掉了很多无关的候选框。此外作者剔除了一个叫做ROI Pooling的网络层，这个网络层可以把不同大小的输入映射到一个固定尺度的特征向量。ROI Pooling层将每个候选区域均匀分成M * N块，对每块进行Max Pooling。将特征图上大小不一的候选区域转变为大小统一的数据，送入下一层。

#### 2.4 SPP-Net

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_6.png)

卷积并不需要固定的图像尺寸，它可以产生任意尺寸的特征图。而另一方面，根据定义，全连接层则需要固定的尺寸输入。因此固定尺寸的问题来源于全连接层，也是网络的最后阶段。

本文引入一种空间金字塔池化（spatial pyramid pooling，SPP）层以移除对网络固定尺寸的限制。一般是将SPP层放在最后一个卷积层之后。SPP层对特征图进行池化，并产生固定长度的输出，这个输出再喂给全连接层（或其他分类器）。换句话说，再网络层次的较后阶段（也就是卷积层和全连接层之间）进行某种信息的“汇总”，可以避免再最开始的时候就进行裁剪或变形。

#### 2.5 Faster RCNN

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_7.png)

Faster R-CNN可以简单的看成是“区域生成网络+Fast R-CNN”的模型，Faster R-CNN设计了提取候选区域的网络（Region Proposal Network，简称RPN）代替了费时的Fast R-CNN中的Selective Search（选择性搜索）方法，使得检测速度大幅提升。

Faster R-CNN是基于RPN提取的候选区检测并识别候选区中的目标。其具体流程大致可概括为：

1. 输入图像

1. 通过区域生成网络RPN生成候选区域

1. 提取特征

1. 分类器分类

1. 回归其回归并进行位置调整

#### 2.6 RPN

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_8.png)

RPN的具体操作流程如下：使用小型网络在最后的卷积特征图上执行滑动扫描，每当滑动网络完全连接到特征图上的n * n窗口，然后将其映射到低维矢量，最后将这个低维矢量发送到两个全连接层。

RPN的工作步骤如下：

- 在特征图上滑动窗口

- 建一个神经网络用于物体分类+框位置的回归

- 滑动窗口的位置提供了物体的大体位置信息

- 框的回归提供了框更精确的位置

#### 2.7 RCNN、FastRCNN、FasterRCNN性能比较

下表对比了RCNN、FastRCNN、FasterRCNN的检测速度：

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_9.png)

### 3. YOLO V1技术原理

#### 3.1 YOLO V1

> YOLO：You Only Look Once


![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_10.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_11.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_12.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_13.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_14.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_15.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_16.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_17.png)

#### 3.2 SSD

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_18.png)

### 4. YOLO V2技术原理

#### 4.1 YOLO V2

DarkNet19：输入是多尺寸，所以可以输入448 * 448大小，使用anchor机制将输入改成416 * 416

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_19.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_20.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_21.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_22.png)

#### 4.2 K-Means

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_23.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_24.png)

#### 4.3 YOLO 9000

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_25.png)

作者提出了一种新的联合训练方法，结合目前物品分类数据集的优点，将其应用于训练目标检测模型。模型可以从目标检测数据集中学会准确定位目标，同时从物品分类数据集中学会识别更多的种类，增强模型的鲁棒性。

使用WordTree将来自各种来源的数据和联合优化技术组合在ImageNet和COCO上同时进行训练。

采用数据集集合方法和联合训练方法，采用ImageNet和COCO数据集训练该模型，使该模型可以识别和检测超过9000种类别。

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_26.png)

这类训练方法有一定的难度。目标识别数据集仅包含常见目标和标签（比如狗，船），分类数据集包含更广和更深的标签。比如狗，ImageNet上包含超过100种狗的类别。如果要联合训练，需要将这些标签进行合并。

大部分分类方法采用softmax输出所有类别的概率。采用softmax的前提假设是类别之间不相互包含（比如，犬和牧羊犬即使相互包含）。因此，需要一个多标签的模型来综合数据集，使类别之间不相互包含。

WordTree是一个视觉概念的分层模型。为了使用WordTree进行分类，作者预测每个节点的条件概率，以得到同义词集合中每个同义词下义词的概率。

在ImageNet和WordTree上预测，大多数ImageNet模型使用一个较大的softmax来徐策概率分布，使用WordTree可以在共同的下义词上执行多次softmax操作。

### 5. YOLO V3技术原理

#### 5.1 YOLO V3

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_27.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_28.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_29.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_30.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_31.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_32.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_33.png)

#### 5.2 Norm

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_34.png)

#### 5.3 Batch Norm

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_35.png)

#### 5.4 Filter Response Norm

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_36.png)

FRN缺少去均值的操作，这可能使得归一化的结果任意的偏移0，如果FRN之后是ReLU激活层，可能产生很多0值，这对于模型训练和性能是不利的。为了解决这个问题，FRN之后采用的阈值化的ReLU，即TLU。

FRN是在H，W两个维度上归一化，一般情况下网络的特征图大小N=H*W，但是有时候可能会出现1*1的情况，比如InceptionV3和VGG网络，此时就比较关键，下图给出了当N=1时不同归一化的结果。

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_37.png)

当值较小时，归一化相当于一个符号函数，这时候梯度几乎为0，严重影响模型训练。

当值较大时，曲线变得更圆滑，此时的梯度利于模型学习。

对于不含有1*1特征的模型，论文中采用的是一个常量值1e-6。值得说明的是IN也是在H，W维度上进行归一化，但是会减去均值，对于N=1的情况归一化的结果是0，但FRN可以避免这个问题。

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_38.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_39.png)

### 6. YOLO V4/V5技术原理

#### 6.1 结构设计

##### 6.1.1 YOLO V3结构

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_40.png)

##### 6.1.2 YOLO V4结构

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_41.png)

##### 6.1.3 YOLO V5结构

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_42.png)

##### 6.1.4 ReLu和Sigmoid激活函数

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_43.png)

##### 6.1.5 Swish激活函数

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_44.png)

##### 6.1.6 Mish激活函数

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_45.png)

##### 6.1.7 HardTanh激活函数

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_46.png)

##### 6.1.8 HardSwish激活函数

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_47.png)

#### 6.2 损失设计

##### 6.2.1 L1、L2、SMOOTH_L1

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_48.png)

##### 6.2.2 IOU_LOSS存在的问题

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_49.png)

##### 6.2.3 GIOU_LOSS

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_50.png)

##### 6.2.4 DIOU_LOSS

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_51.png)

##### 6.2.5 CIOU_LOSS

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_52.png)

##### 6.2.6 NMS

当做NMS时使用DIOU，预测框的中心点不一样，很有可能是两个不同物体的预测框，而非重叠预测框

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_53.png)

本着使用最好的IOU来做NMS，但是由于CIOU有标签，在去除重复的预测框时不能使用，所以使用了DIOU来做NMS。

#### 6.3 数据增强

##### 6.3.1 几何变换

- 随机缩放

- 裁剪

- 翻转

- 旋转

- 平移

##### 6.3.2 光照变换

- 随机亮度

- 对比度

- 色彩度

- 饱和度

- 噪声

##### 6.3.3 遮挡变换

- random erase

随机删除，在图上随机遮挡某一部分的像素。

- cut out

裁剪，按照一定的间隔遮挡N * N像素大小的小格子，是具有规律的，一般是等间距的小格子，N一般是2或4很小的值，类似于给图片加噪声。

- hide and seek

裁剪，按照更大的间隔遮挡N * N像素大小的小格子，是具有规律的，一般是等间距的小格子，N一般取值更大一些。

- grid mask

网络掩码，YOLOV4中的遮挡是由策略的遮挡，而非随机遮挡，采用的方法是先把图像分成不同的格子，然后按照一定的方法去挑选遮挡某些格子，尽量不去遮挡目标。遮挡的效果取决于格子的大小和被遮挡的格子数量。类似于增加正样本的权重（YOLO图像中一般背景面积较大）。

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_54.png)

研究发现，对训练数据进行一定的遮挡，可以提高模型的推理能力。

神经网络具有一定的联想能力：被遮挡的部分和没有遮挡的部分一起传入神经网络，神经网络会通过对相同部位没有遮挡的图像特征的学习，来对相同位置遮挡部分的特征补充。

但是如果遮挡过大，比如遮住了整个目标，网络可能会欠拟合，反而会造成学习不到特征。

总结：恰如其分的遮挡对神经网络是有效的，可以提高模型的推理能力。但如果遮挡过大，会适得其反，使得网络对数据特征学习不够充分。

##### 6.3.4 DropOut

在训练过程中使用DropOut，对特征图随机遮挡。我们认为卷积神经网络对于数据的处理能力是较强的，被遮挡的数据经过卷积神经网络层的学习，会学习到被遮挡的部分，所以需要在特征图上使用DropOut继续遮挡，防止原始图像遮挡效果在特征图上降低甚至消失。

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_55.png)

##### 6.3.5 DropBlock

由于DropOut的遮挡面积太小，相当于特征图上的随机噪声，而我们需要的是连成片的遮挡区域，所以DropOut还是不足以达到真正遮挡的目的。

所以有了DropBlock，把DropOut的点连城块，它的大小和特征图的大小成比例。最后几层一般不适用DropBlock，否则会造成输出特征缺失。

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_56.png)

#### 6.4 效果展示

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_57.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_58.png)

![](../../assets/images/AI/attachments/4.算法课程学习笔记-多目标检测识别_image_59.png)